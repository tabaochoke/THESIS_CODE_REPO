{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-07T02:19:24.306831Z","iopub.status.busy":"2024-03-07T02:19:24.306549Z","iopub.status.idle":"2024-03-07T02:20:20.887492Z","shell.execute_reply":"2024-03-07T02:20:20.886323Z","shell.execute_reply.started":"2024-03-07T02:19:24.306805Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install --quiet evaluate\n","!pip install --quiet googletrans==3.1.0a0\n","!pip install --quiet pyvi\n","!pip install -U sentence-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:20:20.891179Z","iopub.status.busy":"2024-03-07T02:20:20.889795Z","iopub.status.idle":"2024-03-07T02:20:39.913816Z","shell.execute_reply":"2024-03-07T02:20:39.912818Z","shell.execute_reply.started":"2024-03-07T02:20:20.891145Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-07 02:20:30.388903: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 02:20:30.389018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 02:20:30.509107: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from googletrans import Translator\n","import pandas as pd\n","import torch\n","from datasets import load_dataset \n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification , AutoTokenizer , AutoModel\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","from transformers import DataCollatorWithPadding , get_scheduler\n","from torch.utils.data import DataLoader\n","import evaluate\n","from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit , train_test_split\n","import numpy as np\n","from accelerate import Accelerator\n","from pyvi.ViTokenizer import tokenize\n","device = torch.device (\"cuda\") if torch.cuda.is_available() else torch.device (\"cpu\" )\n","# vietnamese_text = \"Xin chào, bạn đang làm gì?\"\n","# english_translation = translate_vietnamese_to_english(vietnamese_text)\n","# print(english_translation)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:20:39.915754Z","iopub.status.busy":"2024-03-07T02:20:39.915034Z","iopub.status.idle":"2024-03-07T02:20:39.941698Z","shell.execute_reply":"2024-03-07T02:20:39.941014Z","shell.execute_reply.started":"2024-03-07T02:20:39.915726Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","from pyvi.ViTokenizer import tokenize"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:20:39.943755Z","iopub.status.busy":"2024-03-07T02:20:39.943492Z","iopub.status.idle":"2024-03-07T02:20:47.471632Z","shell.execute_reply":"2024-03-07T02:20:47.470764Z","shell.execute_reply.started":"2024-03-07T02:20:39.943732Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a17f4c1e64f4f948c59efe6f7af8d64","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba8a8ce8eb88417cad647a85e14bf967","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1555508ce52425eaec12d5ba5feabb7","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe06de6c066d49ba9e1b5abc0f9eb90c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"093077c9e6ca444db9c8a208d7c878b6","version_major":2,"version_minor":0},"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd269ac3ffc64686b77d5e33269553d0","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8768cbb5cb8140fa955fb799900753fd","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"921bfba7fd3243b4afb798b63ca0c857","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"573a519ee3eb47d38322ab4c18dd59c1","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37eac4673a4144c7a3a45041b0894aec","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01eba39dbf0d464c861d1a1e9cdc65dd","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["vi_model =  SentenceTransformer('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')\n","# vi_model =  AutoModel.from_pretrained('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base').to(device)\n","\n","# eng_model = SentenceTransformer ('princeton-nlp/sup-simcse-roberta-base')\n","eng_model = SentenceTransformer ('distilbert/distilbert-base-uncased-finetuned-sst-2-english')\n","# eng_model = AutoModel.from_pretrained ('sentence-transformers/all-mpnet-base-v2')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:20:47.473011Z","iopub.status.busy":"2024-03-07T02:20:47.472712Z","iopub.status.idle":"2024-03-07T02:20:47.724609Z","shell.execute_reply":"2024-03-07T02:20:47.723835Z","shell.execute_reply.started":"2024-03-07T02:20:47.472986Z"},"trusted":true},"outputs":[],"source":["vi_tok = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n","# eng_tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:20:47.726160Z","iopub.status.busy":"2024-03-07T02:20:47.725776Z","iopub.status.idle":"2024-03-07T02:21:32.959397Z","shell.execute_reply":"2024-03-07T02:21:32.958326Z","shell.execute_reply.started":"2024-03-07T02:20:47.726126Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b52220135c2444da7cd00ef41248610","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d2f3e2fd29245339317357664740b10","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/13.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset opus100/default to /root/.cache/huggingface/datasets/opus100/default-language_pair=en-vi/1.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7cd0e874da0e432c86aa8a4212dea63c","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/30.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset opus100 downloaded and prepared to /root/.cache/huggingface/datasets/opus100/default-language_pair=en-vi/1.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3231b765d1df45fca5f8fac3a0099bbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['translation'],\n","    num_rows: 250000\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["en_vi = load_dataset(\"opus100\", language_pair = \"en-vi\")\n","train_data = en_vi[\"train\"].select (range (250000))\n","train_data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:21:32.960812Z","iopub.status.busy":"2024-03-07T02:21:32.960538Z","iopub.status.idle":"2024-03-07T02:21:32.967850Z","shell.execute_reply":"2024-03-07T02:21:32.966944Z","shell.execute_reply.started":"2024-03-07T02:21:32.960788Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'translation': {'en': 'What is it?', 'vi': 'Cái gì đó?'}}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:21:32.969420Z","iopub.status.busy":"2024-03-07T02:21:32.969137Z","iopub.status.idle":"2024-03-07T02:21:32.975690Z","shell.execute_reply":"2024-03-07T02:21:32.974781Z","shell.execute_reply.started":"2024-03-07T02:21:32.969397Z"},"trusted":true},"outputs":[],"source":["#Mean Pooling - Take attention mask into account for correct averaging\n","# def mean_pooling(model_output, attention_mask):\n","#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:21:32.977046Z","iopub.status.busy":"2024-03-07T02:21:32.976774Z","iopub.status.idle":"2024-03-07T02:21:32.988084Z","shell.execute_reply":"2024-03-07T02:21:32.987194Z","shell.execute_reply.started":"2024-03-07T02:21:32.977024Z"},"trusted":true},"outputs":[],"source":["# def tokenize_vi (samples) :\n","#     vi_sen = [tokenize(sentence['vi']) for sentence in samples['translation']]\n","# #     return vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100) \n","#     eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n","#     print (eng_sen)\n","#     1/0\n","#     with torch.no_grad () :\n","#         vi_embedding_list = vi_model.encode (vi_sen)\n","#         en_embedding_list = eng_model.encode (eng_sen)\n","#     return {\"en_emb\" : en_embedding_list , \"vi_emb\" : vi_embedding_list }\n","\n","def embedding_language (samples) :\n","    vi_tokenize = [tokenize(sentence['vi']) for sentence in samples['translation']]\n","    eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n","    with torch.no_grad () :\n","        vi_emb = vi_model.encode ( vi_tokenize)\n","        eng_emb = eng_model.encode(eng_sen)\n","    return {\"vi_emb\" : vi_emb ,\"en_emb\" : eng_emb   }\n","\n","\n","# def embedding_language (samples) :\n","#     vi_tokenize = [tokenize(sentence['vi']) for sentence in samples['translation']]\n","    \n","#     vi_tokenize = vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100 , return_tensors = \"pt\").to(device)\n","    \n","#     eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n","#     with torch.no_grad () :\n","#         vi_emb = vi_model(** vi_tokenize).pooler_output.cpu().numpy().tolist()\n","        \n","#         eng_emb = eng_model.encode(eng_sen)\n","#     return {\"vi_emb\" : vi_emb ,\"en_emb\" : eng_emb   }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T02:21:32.992011Z","iopub.status.busy":"2024-03-07T02:21:32.991687Z"},"trusted":true},"outputs":[],"source":["%%capture\n","vi_tok_data = train_data.map (embedding_language , batched = True  )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len ( vi_tok_data[0]['vi_emb'] )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vi_tok_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_final = vi_tok_data.remove_columns (['translation'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["split_dataset = data_final.train_test_split (train_size = 0.8 ,seed = 42 )\n","split_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Adapter (nn.Module) :\n","    def __init__(self, ):\n","        super(Adapter, self).__init__()\n","        self.linear1 = nn.Linear (768 , 384)\n","        self.linear2 = nn.Linear (384 , 768)\n","        self.layernorm = nn.LayerNorm (384)\n","        self.dropout = nn.Dropout (0.1)\n","        \n","    \n","    def forward(self, vi_emb_stack):\n","        output = self.linear1 (vi_emb_stack)\n","        output = self.layernorm (output)\n","        output = self.dropout (output)\n","        output = self.linear2 (output)\n","        return output\n","adapter = Adapter()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epochs = 5\n","#data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","train_dataloader = DataLoader (split_dataset[\"train\"], batch_size= 128 , shuffle= True )\n","val_dataloader = DataLoader (split_dataset['test'], batch_size= 128 , shuffle= True  )\n","accelerator = Accelerator ()\n","device = torch.device (\"cuda\") if torch.cuda.is_available() else torch.device (\"cpu\" )\n","\n","step_to_train = epochs * len (val_dataloader)\n","optimizer = torch.optim.AdamW (adapter.parameters () , lr = 2e-5)\n","scheduler = get_scheduler (name = \"cosine\" , \n","                           optimizer = optimizer ,\n","                           num_warmup_steps=0,\n","                           num_training_steps = step_to_train\n","                          )\n","\n","train_dataloader , val_dataloader , adapter , optimizer= accelerator.prepare (train_dataloader , val_dataloader , adapter , optimizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np \n","prediction = []\n","criterion = nn.MSELoss()\n","best_val_loss = 0\n","version = 0\n","for epoch in range (epochs) : \n","    train_losses = []\n","    vi_model.train()\n","    for batch in tqdm ( train_dataloader ) :\n","        vi_emb = batch.pop (\"vi_emb\")\n","        en_emb = batch.pop (\"en_emb\")\n","        \n","        vi_emb_stack =  torch.stack (vi_emb , dim = 1).float () .to(device)\n","        en_emb_stack =  torch.stack (en_emb , dim = 1).float () .to(device)\n","        \n","\n","        fake_en_emb = adapter.forward (vi_emb_stack)\n","        loss =  criterion (fake_en_emb , en_emb_stack)\n","\n","        # BACKWARD ADAPTER\n","        accelerator.backward (loss)\n","\n","        optimizer.step ()\n","        scheduler.step ()\n","        \n","        \n","        optimizer.zero_grad ()\n","        \n","        train_losses.append (loss.item())\n","    \n","            #print (outputs.shape , labels.shape)\n","    print (\"TRAINING : Epoch : {}, TRAINING Loss: {}\".format (epoch + 1, np.mean( train_losses) ) )\n","    \n","    vi_model.eval()\n","    val_losses = []\n","    for batch in  tqdm (val_dataloader)  :\n","        \n","        vi_emb = batch.pop (\"vi_emb\")\n","        en_emb = batch.pop (\"en_emb\")\n","        \n","        vi_emb_stack =  torch.stack (vi_emb , dim = 1).float () .to(device)\n","        en_emb_stack =  torch.stack (en_emb , dim = 1).float () .to(device)\n","        \n","\n","        fake_en_emb = adapter.forward (vi_emb_stack)\n","        loss =  criterion (fake_en_emb , en_emb_stack)\n","        val_losses.append (loss.item())\n","    if np.mean( val_losses) > best_val_loss :\n","        torch.save(vi_model.state_dict(), \"vietnam model {}\".format (version))\n","        version +=1\n","        best_val_loss = np.mean( val_losses)\n","    print (\"VALIDATION : Epoch : {}, Val Loss: {} \".format (epoch + 1, np.mean( val_losses) ))\n"]},{"cell_type":"markdown","metadata":{},"source":["# TEST ON UIT STUDENT FEEDBACK"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_link = \"uitnlp/vietnamese_students_feedback\"\n","from datasets import load_dataset\n","dataset = load_dataset(dataset_link)\n","val_data = dataset[\"validation\"]"]},{"cell_type":"markdown","metadata":{},"source":["# PREPROCESS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def del_neutral (samples) :\n","    return samples['sentiment'] == 0 or samples['sentiment'] == 2\n","no_neutral_data = val_data.filter (del_neutral)\n","no_neutral_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num2label = {2 : 1 , 0 : 0 }\n","# data có label là 2 tương ứng positive còn 0 ứng với negative\n","# còn của model là {0: 'NEGATIVE', 1: 'POSITIVE'}\n","def convertlabel (samples) :\n","    return {\"sentiment\" : [num2label [num] for num in samples[\"sentiment\"]] }\n","con_dataset = no_neutral_data.map (convertlabel , batched = True)\n","con_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["con_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["backbone_vi_model =  SentenceTransformer('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')\n","# backbone_vi_model =  AutoModel.from_pretrained('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base').to(device)\n","# vi_tok = AutoTokenizer.from_pretrained (\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["en_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\").to(device)\n","en_tok = AutoTokenizer.from_pretrained (\"distilbert-base-uncased-finetuned-sst-2-english\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def mean_pooling(model_output, attention_mask):\n","#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"]},{"cell_type":"markdown","metadata":{},"source":["# NHỚ PHẢI CHẠY FORWARD ADAPTER SAU KHI TRAIN LẠI ADAPTER MỚI NHAN TRỜI"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def forward_adapter (samples) :\n","    vi_tokenize = [tokenize(sentence) for sentence in samples['sentence']]\n","    with torch.no_grad () :\n","        vi_embedding_list = backbone_vi_model.encode (vi_tokenize)\n","        tensor_samples =  torch.tensor ( vi_embedding_list).to(device)\n","        fake_en_emb =  [ adapter (tensor_sample) for tensor_sample in tensor_samples ] \n","    return {\"en_emb\" :  fake_en_emb}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def forward_adapter_fake (samples) :\n","#     vi_tokenize = [tokenize(sentence) for sentence in samples['sentence']]\n","    \n","#     vi_tokenize = vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100 , return_tensors = \"pt\").to(device)\n","    \n","#     with torch.no_grad () :\n","#         vi_emb = vi_model(** vi_tokenize).pooler_output\n","#         fake_en_emb =  adapter (vi_emb).cpu().numpy().tolist()\n","#     return {\"en_emb\" : fake_en_emb   }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["eval_dataset = con_dataset.map (forward_adapter , batched = True , remove_columns = [\"sentence\" , \"topic\" ])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def forward_adapter (samples) :\n","#     tensor_samples = torch.tensor ( samples[\"vi_emb\"] ).to(device)\n","#     fake_en_emb =  [ adapter (tensor_sample) for tensor_sample in tensor_samples ] \n","#     return {\"en_emb\" :  fake_en_emb}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# en_emb_data = eval_dataset.map (forward_adapter , batched = True , remove_columns = [\"sentence\" , \"topic\" , \"vi_emb\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","val_dataloader = DataLoader (eval_dataset, batch_size= 128, shuffle=True  )\n","#Metric\n","accelerator = Accelerator ()\n","val_dataloader ,adapter= accelerator.prepare ( val_dataloader , adapter )\n","\n","\n","metric_valid_acc = evaluate.load(\"accuracy\")\n","\n","metric_valid_f1 = evaluate.load(\"f1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def vie_emb (samples) :\n","#     vi_tokenize = [tokenize(sentence) for sentence in samples['sentence']]\n","#     token = vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100 , return_tensors = \"pt\") \n","#     vi_emb = vi_model (**token)\n","#     mean_pool_vi = mean_pooling (vi_emb , token[\"attention_mask\"])\n","#     vi_embedding_list = mean_pool_vi.numpy().tolist ()\n","#     return {\"vi_emb\" :vi_embedding_list }\n","#             #, \"en\" : [eng_model ( sample['en'] ) for sample in samples[\"translation\"]] "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# input_dataset = con_dataset.map (vie_emb , batched = True , remove_columns = ['sentence', 'topic'])\n","# input_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def forward_adapter (samples) :\n","#     tensor_samples = torch.tensor ( samples[\"vi_emb\"] ).to(device)\n","#     fake_en_emb =  [ adapter (tensor_sample) for tensor_sample in tensor_samples ] \n","#     return {\"en_emb\" :  fake_en_emb}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["adapter.eval()\n","val_losses = []\n","prediction = []\n","criterion = nn.CrossEntropyLoss()\n","for batch in tqdm ( val_dataloader ) :\n","    with torch.no_grad () :\n","        labels = batch.pop (\"sentiment\").to(device)\n","        en_emb = batch.pop (\"en_emb\")\n","        en_emb_stack = torch.stack (en_emb , dim = 1 ).float ().to(device)\n","        with torch.no_grad () :\n","            output = en_model.pre_classifier.forward (en_emb_stack)\n","            output = en_model.classifier.forward (output)\n","            logits = en_model.dropout.forward(output)\n","        \n","        #print (outputs.shape , labels.shape)\n","        loss = criterion(logits,labels)\n","        predict = torch.argmax (logits, dim = -1)\n","        \n","        \n","        val_losses.append (loss.item())\n","        prediction.append (predict)\n","        metric_valid_acc.add_batch (references=labels, predictions = predict)\n","        metric_valid_f1.add_batch (references=labels, predictions = predict )\n","\n","val_acc = metric_valid_acc.compute ()['accuracy']\n","# if val_acc > best_val_acc :\n","#     torch.save(model.state_dict(), \"Phobert_v2_best_model_full_data_{}\".format (i))\n","#     best_val_acc = val_acc\n","#     i+=1\n","print (\" Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format ( np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"macro\")['f1'] ))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.vilt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
