{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Translation API","metadata":{}},{"cell_type":"code","source":"!pip install --quiet evaluate\n!pip install --quiet googletrans==3.1.0a0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from googletrans import Translator\nimport pandas as pd\nimport torch\nfrom datasets import load_dataset \nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification , AutoTokenizer , AutoModel\nimport torch.nn as nn\nfrom tqdm.auto import tqdm\nfrom transformers import DataCollatorWithPadding , get_scheduler\nfrom torch.utils.data import DataLoader\nimport evaluate\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit , train_test_split\nimport numpy as np\nfrom accelerate import Accelerator\n\ndevice = torch.device (\"cuda\") if torch.cuda.is_available() else torch.device (\"cpu\" )\n# vietnamese_text = \"Xin chào, bạn đang làm gì?\"\n# english_translation = translate_vietnamese_to_english(vietnamese_text)\n# print(english_translation)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Translate + Model ENG","metadata":{}},{"cell_type":"code","source":"dataset_link = \"uitnlp/vietnamese_students_feedback\"\nfrom datasets import load_dataset\ndataset = load_dataset(dataset_link)\ndataset","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TRANSLATE + DELETE NEUTRAL + CONVERT LABEL","metadata":{}},{"cell_type":"code","source":"def translate_vietnamese_to_english(text):\n    translator = Translator()\n    translation = translator.translate(text, src='vi', dest='en')\n    return translation.text","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:45:06.846196Z","iopub.execute_input":"2024-02-28T13:45:06.846963Z","iopub.status.idle":"2024-02-28T13:45:06.851731Z","shell.execute_reply.started":"2024-02-28T13:45:06.846924Z","shell.execute_reply":"2024-02-28T13:45:06.850802Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def del_neutral (samples) :\n    return samples['sentiment'] == 0 or samples['sentiment'] == 2\nno_neutral_data = dataset.filter (del_neutral)\nno_neutral_data","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:45:09.019962Z","iopub.execute_input":"2024-02-28T13:45:09.020324Z","iopub.status.idle":"2024-02-28T13:45:09.219217Z","shell.execute_reply.started":"2024-02-28T13:45:09.020296Z","shell.execute_reply":"2024-02-28T13:45:09.218367Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db551ad7ba7b4911a4e625f0b550385b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a89f0e04924f27be06cc45ac60477d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3c6ddad8234447092d240cd6534a3bb"}},"metadata":{}},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 10968\n    })\n    validation: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 1510\n    })\n    test: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 2999\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"num2label = {2 : 1 , 0 : 0 }\n# data có label là 2 tương ứng positive còn 0 ứng với negative\n# còn của model là {0: 'NEGATIVE', 1: 'POSITIVE'}\ndef convertlabel (samples) :\n    return {\"sentiment\" : [num2label [num] for num in samples[\"sentiment\"]] }\ncon_dataset = no_neutral_data.map (convertlabel , batched = True)\ncon_dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:45:10.730490Z","iopub.execute_input":"2024-02-28T13:45:10.731151Z","iopub.status.idle":"2024-02-28T13:45:11.050548Z","shell.execute_reply.started":"2024-02-28T13:45:10.731119Z","shell.execute_reply":"2024-02-28T13:45:11.049668Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed5a0e19b194431a2dee539d51643b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0292c2d0b0f74a4bb11f87aae4467872"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf497a5099a4dc39415c98ba5613a3b"}},"metadata":{}},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 10968\n    })\n    validation: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 1510\n    })\n    test: Dataset({\n        features: ['sentence', 'sentiment', 'topic'],\n        num_rows: 2999\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def trans_data (samples) :\n    return {\"sentence\" : [translate_vietnamese_to_english (sample ) for sample in  samples[\"sentence\"] ] }","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:45:13.241803Z","iopub.execute_input":"2024-02-28T13:45:13.242849Z","iopub.status.idle":"2024-02-28T13:45:13.249513Z","shell.execute_reply.started":"2024-02-28T13:45:13.242804Z","shell.execute_reply":"2024-02-28T13:45:13.248438Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"#train = con_dataset['train'].map (trans_data , batched = True)\nval = con_dataset['validation'].map (trans_data , batched = True)\n#test = con_dataset['test'].map (trans_data , batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:59:24.680881Z","iopub.execute_input":"2024-03-02T14:59:24.681616Z","iopub.status.idle":"2024-03-02T14:59:24.725722Z","shell.execute_reply.started":"2024-03-02T14:59:24.681586Z","shell.execute_reply":"2024-03-02T14:59:24.724280Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#train = con_dataset['train'].map (trans_data , batched = True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mcon_dataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap (trans_data , batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#test = con_dataset['test'].map (trans_data , batched = True)\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'con_dataset' is not defined"],"ename":"NameError","evalue":"name 'con_dataset' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"###  LOAD MODEL","metadata":{}},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n\n# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n# with torch.no_grad():\n#     logits = model(**inputs).logits\n\n# predicted_class_id = logits.argmax().item()\n# model.config.id2label[predicted_class_id]\n# model.config.id2label","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:59:08.137222Z","iopub.execute_input":"2024-03-02T14:59:08.137988Z","iopub.status.idle":"2024-03-02T14:59:12.877623Z","shell.execute_reply.started":"2024-03-02T14:59:08.137950Z","shell.execute_reply":"2024-03-02T14:59:12.876604Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5280df4c24c041b9bd184213f207cd53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec3752f357944126886ed41f70603f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ae16b3b07943b1bc86bb0b021fb397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"481614680bce4a319fa19744ff4dac77"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(samples) :\n    return tokenizer (samples['sentence'] , truncation = True, max_length = 256  )\n# val_tokenize = val.map (tokenize , batched = True )\nval_tokenize = con_dataset.map (tokenize , batched = True )\n\n\n# val_tokenize = val.map (tokenize , batched = True )\n# test_tokenize = test.map (tokenize , batched = True )","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:59:12.879186Z","iopub.execute_input":"2024-03-02T14:59:12.879475Z","iopub.status.idle":"2024-03-02T14:59:13.464724Z","shell.execute_reply.started":"2024-03-02T14:59:12.879450Z","shell.execute_reply":"2024-03-02T14:59:13.463446Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer (samples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m] , truncation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m  )\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# val_tokenize = val.map (tokenize , batched = True )\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m val_tokenize \u001b[38;5;241m=\u001b[39m \u001b[43mcon_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap (tokenize , batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# val_tokenize = val.map (tokenize , batched = True )\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# test_tokenize = test.map (tokenize , batched = True )\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'con_dataset' is not defined"],"ename":"NameError","evalue":"name 'con_dataset' is not defined","output_type":"error"}]},{"cell_type":"code","source":"val_data = val_tokenize.remove_columns (['sentence' , 'topic'])\nval_data = val_data.rename_column ('sentiment' , 'labels')\nval_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:29:06.117643Z","iopub.status.idle":"2024-03-02T07:29:06.117993Z","shell.execute_reply.started":"2024-03-02T07:29:06.117826Z","shell.execute_reply":"2024-03-02T07:29:06.117839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\nval_dataloader = DataLoader (val_data, batch_size= 256, shuffle=True , collate_fn = data_collator )\n\nmetric_valid_acc = evaluate.load(\"accuracy\")\n\nmetric_valid_f1 = evaluate.load(\"f1\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:26:30.317419Z","iopub.execute_input":"2024-02-27T14:26:30.317707Z","iopub.status.idle":"2024-02-27T14:26:31.702716Z","shell.execute_reply.started":"2024-02-27T14:26:30.317682Z","shell.execute_reply":"2024-02-27T14:26:31.701892Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94abc0aeae484e4f96e1c4c65b85acc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1314c249675847c59e5f9391106ed86f"}},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\nval_losses = []\nprediction = []\nfor batch in tqdm ( val_dataloader ) :\n    with torch.no_grad () :\n        labels = batch.pop (\"labels\")\n        logits = model.forward (**batch).logits\n\n        criterion = nn.CrossEntropyLoss()\n        #print (outputs.shape , labels.shape)\n        loss = criterion(logits,labels)\n        val_losses.append (loss.item())\n\n        predict = torch.argmax (logits, dim = -1)\n        prediction.append (predict)\n        metric_valid_acc.add_batch (references=labels, predictions = predict)\n        metric_valid_f1.add_batch (references=labels, predictions = predict )\n\nval_acc = metric_valid_acc.compute ()['accuracy']\n# if val_acc > best_val_acc :\n#     torch.save(model.state_dict(), \"Phobert_v2_best_model_full_data_{}\".format (i))\n#     best_val_acc = val_acc\n#     i+=1\nprint (\"Epoch : {}, Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format (epoch + 1, np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"macro\")['f1'] ))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:33:05.742603Z","iopub.execute_input":"2024-02-27T14:33:05.743640Z","iopub.status.idle":"2024-02-27T14:33:05.867484Z","shell.execute_reply.started":"2024-02-27T14:33:05.743598Z","shell.execute_reply":"2024-02-27T14:33:05.866282Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71d8e0b2d094e1da34ef3fcca8ba0cc"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad () :\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpop (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m (logits\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: Sequential.forward() got an unexpected keyword argument 'input_ids'"],"ename":"TypeError","evalue":"Sequential.forward() got an unexpected keyword argument 'input_ids'","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nprint (\"Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format ( np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"macro\")['f1'] ))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T09:36:41.182809Z","iopub.execute_input":"2024-02-27T09:36:41.183175Z","iopub.status.idle":"2024-02-27T09:36:41.202300Z","shell.execute_reply.started":"2024-02-27T09:36:41.183145Z","shell.execute_reply":"2024-02-27T09:36:41.201293Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Val Loss: 0.39537401994069415 , Validation  ACC Result : 0.9139072847682119 , Validation F1 Result :0.9126381412173517\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train adapter on Translation data","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U sentence-transformers\n!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:27:12.297636Z","iopub.execute_input":"2024-03-03T03:27:12.298237Z","iopub.status.idle":"2024-03-03T03:27:38.411341Z","shell.execute_reply.started":"2024-03-03T03:27:12.298211Z","shell.execute_reply":"2024-03-03T03:27:38.410053Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom pyvi.ViTokenizer import tokenize","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:27:38.414874Z","iopub.execute_input":"2024-03-03T03:27:38.415251Z","iopub.status.idle":"2024-03-03T03:27:38.506780Z","shell.execute_reply.started":"2024-03-03T03:27:38.415222Z","shell.execute_reply":"2024-03-03T03:27:38.505854Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### LOAD MODEL AND DATASET","metadata":{}},{"cell_type":"markdown","source":"### LOAD Vietnames embedding model and english embedding model. english will be used to creat embedding label (target), apply sentence transformer to this. vietnames will containt the SWITCH for convert vietnames to english later","metadata":{}},{"cell_type":"code","source":"vi_model =  AutoModel.from_pretrained('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')\n# eng_model = SentenceTransformer ('princeton-nlp/sup-simcse-roberta-base')\neng_model = AutoModel.from_pretrained ('distilbert-base-uncased-finetuned-sst-2-english')\n# eng_model = AutoModel.from_pretrained ('sentence-transformers/all-mpnet-base-v2')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:27:38.508002Z","iopub.execute_input":"2024-03-03T03:27:38.508341Z","iopub.status.idle":"2024-03-03T03:27:59.562127Z","shell.execute_reply.started":"2024-03-03T03:27:38.508310Z","shell.execute_reply":"2024-03-03T03:27:59.561255Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c4a84f4b3f548f5af649a3b2a7f781b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8322a0a090dd443bb09e886bfbb9798f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f743be11d804d4fa845b1cef820c561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d713be1f7224a73b0919dd24acefed0"}},"metadata":{}}]},{"cell_type":"code","source":"vi_tok = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\neng_tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n# eng_tok = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:27:59.563375Z","iopub.execute_input":"2024-03-03T03:27:59.563749Z","iopub.status.idle":"2024-03-03T03:28:06.270549Z","shell.execute_reply.started":"2024-03-03T03:27:59.563717Z","shell.execute_reply":"2024-03-03T03:28:06.269747Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f720cfffeccc420cab8b3ba9ffabd711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821e52abce1140289610071d76905b0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741adcd4d09c463992662b53f0cc657c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87baa30f80dd42d7bcc2349244b1a3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48886db7418b4a748d6d73b55b9ad757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26be7e6985ba479592cb9dcfa0a48958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1b4b165d07c44e78baf485e5e47b800"}},"metadata":{}}]},{"cell_type":"code","source":"embedding_en = eng_model.embeddings","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:28:06.271644Z","iopub.execute_input":"2024-03-03T03:28:06.271903Z","iopub.status.idle":"2024-03-03T03:28:06.276350Z","shell.execute_reply.started":"2024-03-03T03:28:06.271881Z","shell.execute_reply":"2024-03-03T03:28:06.275301Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### ADD ADAPTER TO VI MODEL","metadata":{}},{"cell_type":"code","source":"vi_model.embeddings.add_module (module = torch.nn.Sequential (\n    nn.Dropout (0.1)  , \n    nn.Linear (768,768)  ) ,\n    name = \"dropout\" )","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:28:06.277517Z","iopub.execute_input":"2024-03-03T03:28:06.277804Z","iopub.status.idle":"2024-03-03T03:28:06.409027Z","shell.execute_reply.started":"2024-03-03T03:28:06.277779Z","shell.execute_reply":"2024-03-03T03:28:06.408162Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### CREATE EMBEDDING TARGET FOR  ENGLISH","metadata":{}},{"cell_type":"code","source":"# LOAD DATA\nen_vi = load_dataset(\"opus100\", language_pair = \"en-vi\")\ntrain_data = en_vi[\"train\"].select (range (10000))\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:28:06.410159Z","iopub.execute_input":"2024-03-03T03:28:06.410473Z","iopub.status.idle":"2024-03-03T03:29:06.243951Z","shell.execute_reply.started":"2024-03-03T03:28:06.410448Z","shell.execute_reply":"2024-03-03T03:29:06.243062Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca24a713dc7456e8203abcd92801326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/13.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc8c4b7a8cf4b3c95d42d8608117372"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset opus100/default to /root/.cache/huggingface/datasets/opus100/default-language_pair=en-vi/1.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/30.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"967fea12a9584a4aa55332efe4359f52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset opus100 downloaded and prepared to /root/.cache/huggingface/datasets/opus100/default-language_pair=en-vi/1.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d17a6d8097434191fdde24755947d8"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translation'],\n    num_rows: 10000\n})"},"metadata":{}}]},{"cell_type":"code","source":"# def embedding_language (samples) :\n#     vi_tokenize = [tokenize(sentence['vi']) for sentence in samples['translation']]\n#     eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n#     with torch.no_grad () :\n#         vi_emb = vi_model.encode ( vi_tokenize)\n#         eng_emb = eng_model.encode(eng_sen)\n#     return {\"vi_emb\" : vi_emb ,\"en_emb\" : eng_emb   }\n            #, \"en\" : [eng_model ( sample['en'] ) for sample in samples[\"translation\"]] }","metadata":{"execution":{"iopub.status.busy":"2024-03-03T01:23:13.959889Z","iopub.execute_input":"2024-03-03T01:23:13.960756Z","iopub.status.idle":"2024-03-03T01:23:13.964961Z","shell.execute_reply.started":"2024-03-03T01:23:13.960720Z","shell.execute_reply":"2024-03-03T01:23:13.963879Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# %%capture\n# en_vi_emb = en_vi[\"train\"].map (embedding_language , batched = True)\n# len ( en_vi_emb[0]['vi_emb'] )","metadata":{"execution":{"iopub.status.busy":"2024-03-03T01:23:14.318614Z","iopub.execute_input":"2024-03-03T01:23:14.319256Z","iopub.status.idle":"2024-03-03T01:23:15.198748Z","shell.execute_reply.started":"2024-03-03T01:23:14.319225Z","shell.execute_reply":"2024-03-03T01:23:15.197709Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### THIS WILL TOKENIZE VIETNAM AND CREATE EMBEDDING TARGET FOR ENGLISH","metadata":{}},{"cell_type":"code","source":"#Mean Pooling - Take attention mask into account for correct averaging\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:29:06.246750Z","iopub.execute_input":"2024-03-03T03:29:06.247031Z","iopub.status.idle":"2024-03-03T03:29:06.252345Z","shell.execute_reply.started":"2024-03-03T03:29:06.247007Z","shell.execute_reply":"2024-03-03T03:29:06.251423Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# boi vi bi trung ten nen minh se phai tao 2 du lieu tokenize rieng le voi nhau\ndef tokenize_vi (samples) :\n    vi_tokenize = [tokenize(sentence['vi']) for sentence in samples['translation']]\n    return vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100) \n### DATA KHÔNG CÙNG SHAPE.p\n# def tokenize_en (samples) :\n#     eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n#     with torch.no_grad () :\n#         eng_tokenizer = eng_tok (eng_sen, padding = \"max_length\", truncation= True , max_length = 100 , return_tensors = \"pt\")\n#         eng_embedding = eng_model (**eng_tokenizer)\n# #         embedding_list = [tensor.tolist() for tensor in eng_embedding]\n\n#         sentence_embeddings = mean_pooling(eng_embedding, eng_tokenizer['attention_mask'])\n#         embedding_list = sentence_embeddings.numpy().tolist ()\n#     return {\"en_emb\" : embedding_list }\n\n\ndef tokenize_en (samples) :\n    eng_sen = [sample['en']  for sample in samples[\"translation\"]]\n    with torch.no_grad () :\n        eng_tokenizer = eng_tok (eng_sen, padding = \"max_length\", truncation= True , max_length = 100 , return_tensors = \"pt\")\n        eng_embedding = embedding_en.forward (eng_tokenizer['input_ids'])\n#         embedding_list = [tensor.tolist() for tensor in eng_embedding]\n\n#         sentence_embeddings = mean_pooling(eng_embedding, eng_tokenizer['attention_mask'])\n        print (eng_embedding.shape)\n        embedding_list = eng_embedding.numpy().tolist ()\n    return {\"en_emb\" : embedding_list }","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:29:06.253643Z","iopub.execute_input":"2024-03-03T03:29:06.253944Z","iopub.status.idle":"2024-03-03T03:29:06.262912Z","shell.execute_reply.started":"2024-03-03T03:29:06.253920Z","shell.execute_reply":"2024-03-03T03:29:06.261915Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vi_tok_data = train_data.map (tokenize_vi , batched = True  )","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:29:06.263965Z","iopub.execute_input":"2024-03-03T03:29:06.264281Z","iopub.status.idle":"2024-03-03T03:29:09.577808Z","shell.execute_reply.started":"2024-03-03T03:29:06.264258Z","shell.execute_reply":"2024-03-03T03:29:09.577037Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea9c05e6903b431198cd727c31edcc82"}},"metadata":{}}]},{"cell_type":"code","source":"# import numpy as np\n# a = np.array ( [len ( vi_tok_data[i]['input_ids'] ) for i in range (2000)] )\n# a.min()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T02:49:14.278757Z","iopub.execute_input":"2024-03-03T02:49:14.279043Z","iopub.status.idle":"2024-03-03T02:49:14.283894Z","shell.execute_reply.started":"2024-03-03T02:49:14.279019Z","shell.execute_reply":"2024-03-03T02:49:14.282229Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"vi_en_tok_data = vi_tok_data.map (tokenize_en , batched = True , remove_columns = [\"translation\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:29:09.578872Z","iopub.execute_input":"2024-03-03T03:29:09.579136Z","iopub.status.idle":"2024-03-03T03:31:08.455418Z","shell.execute_reply.started":"2024-03-03T03:29:09.579114Z","shell.execute_reply":"2024-03-03T03:31:08.454584Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d29c83296154f22b25c579c59fa539d"}},"metadata":{}},{"name":"stdout","text":"torch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\ntorch.Size([1000, 100, 768])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### SPLIT DATA","metadata":{}},{"cell_type":"code","source":"split_dataset = vi_en_tok_data.train_test_split (train_size = 0.9 ,seed = 42 )\nsplit_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:31:08.456498Z","iopub.execute_input":"2024-03-03T03:31:08.456823Z","iopub.status.idle":"2024-03-03T03:31:08.476287Z","shell.execute_reply.started":"2024-03-03T03:31:08.456799Z","shell.execute_reply":"2024-03-03T03:31:08.475390Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'en_emb'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'en_emb'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### TRAIN ADAPTER","metadata":{}},{"cell_type":"code","source":"# class Adapter (nn.Module) :\n#     def __init__(self, ):\n#         super(Adapter, self).__init__()\n#         self.adapter = nn.Linear (768 , 768)\n    \n#     def forward(self, vi_emb_stack):\n#         fake_en_emb = self.adapter (vi_emb_stack) \n#         return fake_en_emb\n# adapter = Adapter()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T15:10:00.411192Z","iopub.execute_input":"2024-03-02T15:10:00.411638Z","iopub.status.idle":"2024-03-02T15:10:00.416694Z","shell.execute_reply.started":"2024-03-02T15:10:00.411599Z","shell.execute_reply":"2024-03-02T15:10:00.415669Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Freeze Layers","metadata":{}},{"cell_type":"code","source":"vi_model = vi_model.embeddings","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:31:12.490739Z","iopub.execute_input":"2024-03-03T03:31:12.491101Z","iopub.status.idle":"2024-03-03T03:31:12.496249Z","shell.execute_reply.started":"2024-03-03T03:31:12.491074Z","shell.execute_reply":"2024-03-03T03:31:12.495362Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"vi_model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:33:56.433629Z","iopub.execute_input":"2024-03-03T03:33:56.434048Z","iopub.status.idle":"2024-03-03T03:33:56.440309Z","shell.execute_reply.started":"2024-03-03T03:33:56.434023Z","shell.execute_reply":"2024-03-03T03:33:56.439301Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"RobertaEmbeddings(\n  (word_embeddings): Embedding(64001, 768, padding_idx=1)\n  (position_embeddings): Embedding(258, 768, padding_idx=1)\n  (token_type_embeddings): Embedding(1, 768)\n  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (dropout): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=768, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for params in vi_model.parameters() :\n    params.requires_grad = False\n\n# for params in vi_model.embeddings.dropout.parameters() :\n#     params.requires_grad = True\nfor params in vi_model.dropout.parameters() :\n    params.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:33:58.235428Z","iopub.execute_input":"2024-03-03T03:33:58.235839Z","iopub.status.idle":"2024-03-03T03:33:58.240859Z","shell.execute_reply.started":"2024-03-03T03:33:58.235810Z","shell.execute_reply":"2024-03-03T03:33:58.239912Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"vi_model.train()\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\ndef count_trainable_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint_trainable_parameters (vi_model)\ncount_trainable_params (vi_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:33:59.701207Z","iopub.execute_input":"2024-03-03T03:33:59.702055Z","iopub.status.idle":"2024-03-03T03:33:59.712785Z","shell.execute_reply.started":"2024-03-03T03:33:59.702022Z","shell.execute_reply":"2024-03-03T03:33:59.711697Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"trainable params: 590592 || all params: 49943808 || trainable%: 1.1825129553597515\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"590592"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training Arguments","metadata":{}},{"cell_type":"code","source":"# def collate_tokenize(data):\n#     text_batch = [element[\"text\"] for element in data]\n#     tokenized = tokenizer(text_batch, padding='longest', truncation=True, return_tensors='pt')\n#     return tokenized","metadata":{"execution":{"iopub.status.busy":"2024-03-02T15:10:00.456559Z","iopub.execute_input":"2024-03-02T15:10:00.457169Z","iopub.status.idle":"2024-03-02T15:10:00.467024Z","shell.execute_reply.started":"2024-03-02T15:10:00.457137Z","shell.execute_reply":"2024-03-02T15:10:00.466217Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n#data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\ntrain_dataloader = DataLoader (split_dataset[\"train\"], batch_size= 128 , shuffle= False ,collate_fn=lambda x: x)\nval_dataloader = DataLoader (split_dataset['test'], batch_size= 128 , shuffle= False   , collate_fn=lambda x: x )\naccelerator = Accelerator ()\ndevice = torch.device (\"cuda\") if torch.cuda.is_available() else torch.device (\"cpu\" )\n\nstep_to_train = epochs * len (val_dataloader)\noptimizer = torch.optim.AdamW (vi_model.parameters () , lr = 1e-4)\nscheduler = get_scheduler (name = \"cosine\" , \n                           optimizer = optimizer ,\n                           num_warmup_steps=0,\n                           num_training_steps = step_to_train\n                          )\n\ntrain_dataloader , val_dataloader ,vi_model , optimizer= accelerator.prepare (train_dataloader , val_dataloader , vi_model , optimizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:34:01.903833Z","iopub.execute_input":"2024-03-03T03:34:01.904232Z","iopub.status.idle":"2024-03-03T03:34:02.111749Z","shell.execute_reply.started":"2024-03-03T03:34:01.904202Z","shell.execute_reply":"2024-03-03T03:34:02.110728Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"split_dataset[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:34:03.227381Z","iopub.execute_input":"2024-03-03T03:34:03.228224Z","iopub.status.idle":"2024-03-03T03:34:03.233939Z","shell.execute_reply.started":"2024-03-03T03:34:03.228193Z","shell.execute_reply":"2024-03-03T03:34:03.232980Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'en_emb'],\n    num_rows: 9000\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### TRAINING AND EVALUATION","metadata":{}},{"cell_type":"code","source":"import numpy as np \nprediction = []\ncriterion = nn.MSELoss()\nbest_val_loss = 0\nversion = 0\nfor epoch in range (epochs) : \n    train_losses = []\n    vi_model.train()\n    for batch in tqdm ( train_dataloader ) :\n#         translation = batch.pop (\"translation\")\n#         print (translation)\n#         eng_sen = translation['en'] \n#         print (eng_sen)\n#         with torch.no_grad () :\n#             eng_embedding = eng_model.encode(eng_sen)\n#         en_emb_stack = torch.tensor ( eng_embedding ).to(device)\n\n\n#         vi_emb = batch.pop (\"vi_emb\")\n#         vi_emb_stack = torch.stack (vi_emb , dim = 1).float () .to(device)\n        #FORWARD vimodel\n        en_emb = [sample ['en_emb'] for sample in batch]\n        en_emb = torch.tensor (en_emb).to(device)\n\n        input_ids = [sample ['input_ids'] for sample in batch]\n        input_ids = torch.tensor (input_ids).to(device)\n        \n#         token_type_ids = [sample ['token_type_ids'] for sample in batch]\n#         token_type_ids = torch.tensor (token_type_ids).to(device)\n        \n#         attention_mask = [sample ['attention_mask'] for sample in batch]\n#         attention_mask = torch.tensor (attention_mask).to(device)\n        \n        inputs = {\"input_ids\" : input_ids , \"token_type_ids\" : token_type_ids , \"attention_mask\" : attention_mask}\n        #print (en_emb.shape)\n        #batch = [{ 'input_ids' : sample['input_ids'] ,'token_type_ids' : sample['token_type_ids'] ,'attention_mask' : sample['attention_mask'] } for sample in batch ]\n        \n#         fake_en_emb =  vi_model(**inputs).pooler_output\n        fake_en_emb =  vi_model.forward(inputs['input_ids'])\n        loss =  criterion (fake_en_emb , en_emb)\n\n        # BACKWARD ADAPTER\n        accelerator.backward (loss)\n\n        optimizer.step ()\n        scheduler.step ()\n        \n        \n        optimizer.zero_grad ()\n        \n        train_losses.append (loss.item())\n    \n            #print (outputs.shape , labels.shape)\n    print (\"TRAINING : Epoch : {}, TRAINING Loss: {}\".format (epoch + 1, np.mean( train_losses) ) )\n    \n    vi_model.eval()\n    val_losses = []\n    for batch in  tqdm (val_dataloader)  :\n        \n        en_emb = [sample ['en_emb'] for sample in batch]\n        en_emb = torch.tensor (en_emb).to(device)\n\n        input_ids = [sample ['input_ids'] for sample in batch]\n        input_ids = torch.tensor (input_ids).to(device)\n        \n#         token_type_ids = [sample ['token_type_ids'] for sample in batch]\n#         token_type_ids = torch.tensor (token_type_ids).to(device)\n        \n#         attention_mask = [sample ['attention_mask'] for sample in batch]\n#         attention_mask = torch.tensor (attention_mask).to(device)\n        \n        inputs = {\"input_ids\" : input_ids , \"token_type_ids\" : token_type_ids , \"attention_mask\" : attention_mask}\n        #print (en_emb.shape)\n        #batch = [{ 'input_ids' : sample['input_ids'] ,'token_type_ids' : sample['token_type_ids'] ,'attention_mask' : sample['attention_mask'] } for sample in batch ]\n#         fake_en_emb =  vi_model(**inputs).pooler_output\n        fake_en_emb =  vi_model.forward(inputs['input_ids'])\n        loss =  criterion (fake_en_emb , en_emb)\n        \n        val_losses.append (loss.item())\n    if np.mean( val_losses) > best_val_loss :\n        torch.save(vi_model.state_dict(), \"vietnam model {}\".format (version))\n        version +=1\n        best_val_loss = np.mean( val_losses)\n    print (\"VALIDATION : Epoch : {}, Val Loss: {} \".format (epoch + 1, np.mean( val_losses) ))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:39:17.777651Z","iopub.execute_input":"2024-03-03T03:39:17.777995Z","iopub.status.idle":"2024-03-03T04:53:58.643585Z","shell.execute_reply.started":"2024-03-03T03:39:17.777971Z","shell.execute_reply":"2024-03-03T04:53:58.641737Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/71 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7316bd1b24a44b0f8786040dc78815fd"}},"metadata":{}},{"name":"stdout","text":"TRAINING : Epoch : 1, TRAINING Loss: 0.12190445365620331\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a2a1773de04f94b5860f8bc384d75c"}},"metadata":{}},{"name":"stdout","text":"VALIDATION : Epoch : 1, Val Loss: 0.0959094287827611 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/71 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166271896d084bf980b348114f176a09"}},"metadata":{}},{"name":"stdout","text":"TRAINING : Epoch : 2, TRAINING Loss: 0.08362030699639253\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88679e94710848618b1ad7384a78c8d3"}},"metadata":{}},{"name":"stdout","text":"VALIDATION : Epoch : 2, Val Loss: 0.07389085739850998 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/71 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209a45daa6b34e319f84b2afdfcc12a7"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     vi_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm ( train_dataloader ) :\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         translation = batch.pop (\"translation\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         print (translation)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         eng_sen = translation['en'] \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         print (eng_sen)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         with torch.no_grad () :\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#             eng_embedding = eng_model.encode(eng_sen)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#         en_emb_stack = torch.tensor ( eng_embedding ).to(device)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         vi_emb = batch.pop (\"vi_emb\")\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         vi_emb_stack = torch.stack (vi_emb , dim = 1).float () .to(device)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m#FORWARD vimodel\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         en_emb \u001b[38;5;241m=\u001b[39m [sample [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_emb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     23\u001b[0m         en_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor (en_emb)\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:461\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 461\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:281\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:310\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 310\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoded:\n\u001b[1;32m    312\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:140\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Test Adapter on Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"!pip install --quiet pyvi\nfrom pyvi.ViTokenizer import tokenize","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:54:04.510482Z","iopub.execute_input":"2024-03-03T04:54:04.511386Z","iopub.status.idle":"2024-03-03T04:54:17.122963Z","shell.execute_reply.started":"2024-03-03T04:54:04.511353Z","shell.execute_reply":"2024-03-03T04:54:17.121795Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"dataset_link = \"uitnlp/vietnamese_students_feedback\"\nfrom datasets import load_dataset\ndataset = load_dataset(dataset_link)\nval_data = dataset[\"validation\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:56:29.170615Z","iopub.execute_input":"2024-03-03T04:56:29.171421Z","iopub.status.idle":"2024-03-03T04:56:30.550875Z","shell.execute_reply.started":"2024-03-03T04:56:29.171390Z","shell.execute_reply":"2024-03-03T04:56:30.549899Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f548f46aad496a96815bf738fd7b07"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocess Data","metadata":{}},{"cell_type":"code","source":"def del_neutral (samples) :\n    return samples['sentiment'] == 0 or samples['sentiment'] == 2\nno_neutral_data = val_data.filter (del_neutral)\nno_neutral_data","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:09.406706Z","iopub.execute_input":"2024-03-03T04:55:09.406990Z","iopub.status.idle":"2024-03-03T04:55:09.451654Z","shell.execute_reply.started":"2024-03-03T04:55:09.406966Z","shell.execute_reply":"2024-03-03T04:55:09.450739Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e7261b187e4c599c061a71c9b1f210"}},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence', 'sentiment', 'topic'],\n    num_rows: 1510\n})"},"metadata":{}}]},{"cell_type":"code","source":"num2label = {2 : 1 , 0 : 0 }\n# data có label là 2 tương ứng positive còn 0 ứng với negative\n# còn của model là {0: 'NEGATIVE', 1: 'POSITIVE'}\ndef convertlabel (samples) :\n    return {\"sentiment\" : [num2label [num] for num in samples[\"sentiment\"]] }\ncon_dataset = no_neutral_data.map (convertlabel , batched = True)\ncon_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:09.452821Z","iopub.execute_input":"2024-03-03T04:55:09.453431Z","iopub.status.idle":"2024-03-03T04:55:09.507408Z","shell.execute_reply.started":"2024-03-03T04:55:09.453398Z","shell.execute_reply":"2024-03-03T04:55:09.506596Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5b0da2e26e44ba9b628a38045a39253"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence', 'sentiment', 'topic'],\n    num_rows: 1510\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Embedding VietNam Data","metadata":{}},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n# model = AutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T02:14:14.559943Z","iopub.execute_input":"2024-03-03T02:14:14.560616Z","iopub.status.idle":"2024-03-03T02:14:14.564887Z","shell.execute_reply.started":"2024-03-03T02:14:14.560587Z","shell.execute_reply":"2024-03-03T02:14:14.563828Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# vietnam_model =  SentenceTransformer('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T02:14:14.707087Z","iopub.execute_input":"2024-03-03T02:14:14.707852Z","iopub.status.idle":"2024-03-03T02:14:14.711996Z","shell.execute_reply.started":"2024-03-03T02:14:14.707799Z","shell.execute_reply":"2024-03-03T02:14:14.710941Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# model = AutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n#vi_tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n# the model will be english but the tokenizer and embedding is vietnames","metadata":{"execution":{"iopub.status.busy":"2024-03-02T13:14:14.265281Z","iopub.execute_input":"2024-03-02T13:14:14.265583Z","iopub.status.idle":"2024-03-02T13:14:14.791485Z","shell.execute_reply.started":"2024-03-02T13:14:14.265557Z","shell.execute_reply":"2024-03-02T13:14:14.790238Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb851304c25d4600864c9f9c0c26acde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"485a1eb642cb4cb1bca0b4855a42ac6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b46e987b6c406ebcd61c6d7573f442"}},"metadata":{}}]},{"cell_type":"code","source":"# def embedding_language (samples) :\n#     vi_tokenize = [tokenize(sentence) for sentence in samples['sentence']]\n#     with torch.no_grad () :\n#         vi_emb = vietnam_model.encode ( vi_tokenize)\n#     return {\"vi_emb\" : vi_emb}\n            #, \"en\" : [eng_model ( sample['en'] ) for sample in samples[\"translation\"]] }","metadata":{"execution":{"iopub.status.busy":"2024-03-02T13:14:14.794928Z","iopub.execute_input":"2024-03-02T13:14:14.795598Z","iopub.status.idle":"2024-03-02T13:14:14.799525Z","shell.execute_reply.started":"2024-03-02T13:14:14.795565Z","shell.execute_reply":"2024-03-02T13:14:14.798650Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# emb_data = con_dataset.map (embedding_language , batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T13:14:14.801097Z","iopub.execute_input":"2024-03-02T13:14:14.801492Z","iopub.status.idle":"2024-03-02T13:14:14.820656Z","shell.execute_reply.started":"2024-03-02T13:14:14.801458Z","shell.execute_reply":"2024-03-02T13:14:14.819711Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vi_tok = AutoTokenizer.from_pretrained (\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:10.945685Z","iopub.execute_input":"2024-03-03T04:55:10.946378Z","iopub.status.idle":"2024-03-03T04:55:11.351946Z","shell.execute_reply.started":"2024-03-03T04:55:10.946341Z","shell.execute_reply":"2024-03-03T04:55:11.351079Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def tokenize_language (samples) :\n    vi_tokenize = [tokenize(sentence) for sentence in samples['sentence']]\n    return vi_tok(vi_tokenize, padding = \"max_length\", truncation= True , max_length = 100) \n            #, \"en\" : [eng_model ( sample['en'] ) for sample in samples[\"translation\"]] ","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:11.353434Z","iopub.execute_input":"2024-03-03T04:55:11.353834Z","iopub.status.idle":"2024-03-03T04:55:11.358889Z","shell.execute_reply.started":"2024-03-03T04:55:11.353807Z","shell.execute_reply":"2024-03-03T04:55:11.357962Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"con_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:13.569348Z","iopub.execute_input":"2024-03-03T04:55:13.569723Z","iopub.status.idle":"2024-03-03T04:55:13.575373Z","shell.execute_reply.started":"2024-03-03T04:55:13.569694Z","shell.execute_reply":"2024-03-03T04:55:13.574570Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence', 'sentiment', 'topic'],\n    num_rows: 1510\n})"},"metadata":{}}]},{"cell_type":"code","source":"input_dataset = con_dataset.map (tokenize_language , batched = True , remove_columns = ['sentence', 'topic'])\ninput_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:13.934415Z","iopub.execute_input":"2024-03-03T04:55:13.935357Z","iopub.status.idle":"2024-03-03T04:55:14.666515Z","shell.execute_reply.started":"2024-03-03T04:55:13.935324Z","shell.execute_reply":"2024-03-03T04:55:14.665512Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a32b97c196094ad294774adb3eeb6f54"}},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentiment', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 1510\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Forward VIE embedding through adapter to create fake en_emb","metadata":{}},{"cell_type":"code","source":"# def forward_adapter (samples) :\n#     tensor_samples = torch.tensor ( samples[\"vi_emb\"] ).to(device)\n#     fake_en_emb =  [ adapter (tensor_sample) for tensor_sample in tensor_samples ] \n#     return {\"en_emb\" :  fake_en_emb}","metadata":{"execution":{"iopub.status.busy":"2024-02-29T06:57:04.585075Z","iopub.execute_input":"2024-02-29T06:57:04.585789Z","iopub.status.idle":"2024-02-29T06:57:04.590733Z","shell.execute_reply.started":"2024-02-29T06:57:04.585755Z","shell.execute_reply":"2024-02-29T06:57:04.589799Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# en_emb_data = emb_data.map (forward_adapter , batched = True , remove_columns = [\"sentence\" , \"topic\" , \"vi_emb\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T06:57:04.591937Z","iopub.execute_input":"2024-02-29T06:57:04.592212Z","iopub.status.idle":"2024-02-29T06:57:05.980275Z","shell.execute_reply.started":"2024-02-29T06:57:04.592189Z","shell.execute_reply":"2024-02-29T06:57:05.979540Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f8b27ff1e246dfad0017eaef984da2"}},"metadata":{}}]},{"cell_type":"code","source":"# en_emb_data","metadata":{"execution":{"iopub.status.busy":"2024-02-29T06:57:05.981413Z","iopub.execute_input":"2024-02-29T06:57:05.981723Z","iopub.status.idle":"2024-02-29T06:57:05.987764Z","shell.execute_reply.started":"2024-02-29T06:57:05.981697Z","shell.execute_reply":"2024-02-29T06:57:05.986849Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentiment', 'en_emb'],\n    num_rows: 1510\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## classification","metadata":{}},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:16.798584Z","iopub.execute_input":"2024-03-03T04:55:16.798965Z","iopub.status.idle":"2024-03-03T04:55:17.460931Z","shell.execute_reply.started":"2024-03-03T04:55:16.798930Z","shell.execute_reply":"2024-03-03T04:55:17.459800Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:17.462792Z","iopub.execute_input":"2024-03-03T04:55:17.463106Z","iopub.status.idle":"2024-03-03T04:55:17.470025Z","shell.execute_reply.started":"2024-03-03T04:55:17.463078Z","shell.execute_reply":"2024-03-03T04:55:17.469135Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.distilbert.add_module (module = vi_model , name = \"embeddings\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:40.035132Z","iopub.execute_input":"2024-03-03T04:55:40.035972Z","iopub.status.idle":"2024-03-03T04:55:40.040849Z","shell.execute_reply.started":"2024-03-03T04:55:40.035937Z","shell.execute_reply":"2024-03-03T04:55:40.039996Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"vi_model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:41.509436Z","iopub.execute_input":"2024-03-03T04:55:41.509828Z","iopub.status.idle":"2024-03-03T04:55:41.515787Z","shell.execute_reply.started":"2024-03-03T04:55:41.509798Z","shell.execute_reply":"2024-03-03T04:55:41.514917Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"RobertaEmbeddings(\n  (word_embeddings): Embedding(64001, 768, padding_idx=1)\n  (position_embeddings): Embedding(258, 768, padding_idx=1)\n  (token_type_embeddings): Embedding(1, 768)\n  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (dropout): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=768, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.distilbert.embeddings","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:43.090399Z","iopub.execute_input":"2024-03-03T04:55:43.091069Z","iopub.status.idle":"2024-03-03T04:55:43.098837Z","shell.execute_reply.started":"2024-03-03T04:55:43.091030Z","shell.execute_reply":"2024-03-03T04:55:43.097916Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"RobertaEmbeddings(\n  (word_embeddings): Embedding(64001, 768, padding_idx=1)\n  (position_embeddings): Embedding(258, 768, padding_idx=1)\n  (token_type_embeddings): Embedding(1, 768)\n  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (dropout): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=768, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:46.189247Z","iopub.execute_input":"2024-03-03T04:55:46.190171Z","iopub.status.idle":"2024-03-03T04:55:46.196821Z","shell.execute_reply.started":"2024-03-03T04:55:46.190136Z","shell.execute_reply":"2024-03-03T04:55:46.195790Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Sequential(\n        (0): Dropout(p=0.1, inplace=False)\n        (1): Linear(in_features=768, out_features=768, bias=True)\n      )\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer= vi_tok)\n\nval_dataloader = DataLoader (input_dataset, batch_size= 128, shuffle=True ,  collate_fn = data_collator )\n#Metric\naccelerator = Accelerator ()\nval_dataloader ,model= accelerator.prepare ( val_dataloader , model )\n\n\nmetric_valid_acc = evaluate.load(\"accuracy\")\n\nmetric_valid_f1 = evaluate.load(\"f1\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:55:48.133447Z","iopub.execute_input":"2024-03-03T04:55:48.134316Z","iopub.status.idle":"2024-03-03T04:55:51.098320Z","shell.execute_reply.started":"2024-03-03T04:55:48.134282Z","shell.execute_reply":"2024-03-03T04:55:51.097392Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69960a4a9a0545c59b102d2236918a38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0c7a051a47e4601ba97bd7603d2fad5"}},"metadata":{}}]},{"cell_type":"code","source":"# model.eval()\n# val_losses = []\n# prediction = []\n# criterion = nn.CrossEntropyLoss()\n# for batch in tqdm ( val_dataloader ) :\n#     with torch.no_grad () :\n#         labels = batch.pop (\"sentiment\").to(device)\n#         en_emb = batch.pop (\"en_emb\")\n#         en_emb_stack = torch.stack (en_emb , dim = 1 ).float ().to(device)\n#         with torch.no_grad () :\n#             output = model.pre_classifier.forward (en_emb_stack)\n#             output = model.classifier.forward (output)\n#             logits = model.dropout.forward(output)\n        \n#         #print (outputs.shape , labels.shape)\n#         loss = criterion(logits,labels)\n#         predict = torch.argmax (logits, dim = -1)\n        \n        \n#         val_losses.append (loss.item())\n#         prediction.append (predict)\n#         metric_valid_acc.add_batch (references=labels, predictions = predict)\n#         metric_valid_f1.add_batch (references=labels, predictions = predict )\n\n# val_acc = metric_valid_acc.compute ()['accuracy']\n# # if val_acc > best_val_acc :\n# #     torch.save(model.state_dict(), \"Phobert_v2_best_model_full_data_{}\".format (i))\n# #     best_val_acc = val_acc\n# #     i+=1\n# print (\"Epoch : {}, Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format (epoch + 1, np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"macro\")['f1'] ))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:45:28.898033Z","iopub.execute_input":"2024-02-29T07:45:28.898947Z","iopub.status.idle":"2024-02-29T07:45:36.975204Z","shell.execute_reply.started":"2024-02-29T07:45:28.898915Z","shell.execute_reply":"2024-02-29T07:45:36.974306Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/755 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f82633060d4c0da3dd478d3e445e79"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function tqdm.__del__ at 0x7f4a7b3904c0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1149, in __del__\n    self.close()\n  File \"/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py\", line 278, in close\n    self.disp(bar_style='danger', check_delay=False)\nAttributeError: 'tqdm' object has no attribute 'disp'\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 1, Val Loss: 0.2886639424579897 , Validation  ACC Result : 0.8933774834437086 , Validation F1 Result :0.8912128573864148\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.save(adapter.state_dict(), \"adapter \" )","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:59:45.556971Z","iopub.execute_input":"2024-02-29T07:59:45.557693Z","iopub.status.idle":"2024-02-29T07:59:45.566438Z","shell.execute_reply.started":"2024-02-29T07:59:45.557662Z","shell.execute_reply":"2024-02-29T07:59:45.565497Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.eval()\nval_losses = []\nprediction = []\nepoch = 0\ncriterion = nn.CrossEntropyLoss()\nfor batch in tqdm ( val_dataloader ) :\n    with torch.no_grad () :\n        batch.pop (\"token_type_ids\")\n        labels = batch.pop (\"sentiment\").to(\"cuda\")\n        logits = model(**batch).logits\n        #print (outputs.shape , labels.shape)\n        loss = criterion(logits,labels)\n        predict = torch.argmax (logits, dim = -1)\n        \n        \n        val_losses.append (loss.item())\n        prediction.append (predict)\n        metric_valid_acc.add_batch (references=labels, predictions = predict)\n        metric_valid_f1.add_batch (references=labels, predictions = predict )\n\nval_acc = metric_valid_acc.compute ()['accuracy']\n# if val_acc > best_val_acc :\n#     torch.save(model.state_dict(), \"Phobert_v2_best_model_full_data_{}\".format (i))\n#     best_val_acc = val_acc\n#     i+=1\nprint (\"Epoch : {}, Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format (epoch + 1, np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"macro\")['f1'] ))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:56:39.155981Z","iopub.execute_input":"2024-03-03T04:56:39.156356Z","iopub.status.idle":"2024-03-03T04:56:41.988887Z","shell.execute_reply.started":"2024-03-03T04:56:39.156328Z","shell.execute_reply":"2024-03-03T04:56:41.988041Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"540f1f867cf242218061797ade638758"}},"metadata":{}},{"name":"stdout","text":"Epoch : 1, Val Loss: 2.183247764905294 , Validation  ACC Result : 0.47218543046357614 , Validation F1 Result :0.34134790887114563\n","output_type":"stream"}]},{"cell_type":"code","source":"val_acc","metadata":{"execution":{"iopub.status.busy":"2024-03-02T13:15:10.361541Z","iopub.execute_input":"2024-03-02T13:15:10.362266Z","iopub.status.idle":"2024-03-02T13:15:10.368228Z","shell.execute_reply.started":"2024-03-02T13:15:10.362232Z","shell.execute_reply":"2024-03-02T13:15:10.367338Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.5"},"metadata":{}}]},{"cell_type":"markdown","source":"## TEST ","metadata":{}},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\nimg_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n\nquestion = \"how many dogs are in the picture?\"\ninputs = processor(raw_image, question, return_tensors=\"pt\")\n\nout = model.generate(**inputs)\nprint(processor.decode(out[0], skip_special_tokens=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:37:23.559012Z","iopub.execute_input":"2024-03-02T05:37:23.559942Z","iopub.status.idle":"2024-03-02T05:37:34.738007Z","shell.execute_reply.started":"2024-03-02T05:37:23.559910Z","shell.execute_reply":"2024-03-02T05:37:34.737280Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab18a05b29bf4379ab81e3453f543e5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bb64d9771e41d592dcd9cbc8a02f26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ebb86a95d64ca3b80f25800fc24012"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b05f99a8584c1db4ef9e1ea7fc0c2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bb74130bedb4b2d9c2d3a48690b2dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d03b1b532e54184b9712fb048b55b26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aeb88479bc84602af787b00c00ed14a"}},"metadata":{}},{"name":"stdout","text":"1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1128: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:32:22.532185Z","iopub.execute_input":"2024-02-29T08:32:22.532583Z","iopub.status.idle":"2024-02-29T08:32:22.550926Z","shell.execute_reply.started":"2024-02-29T08:32:22.532532Z","shell.execute_reply":"2024-02-29T08:32:22.550039Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'pixel_values': tensor([[[[ 0.8647,  0.9230,  0.9376,  ...,  1.7552,  1.7552,  1.7552],\n          [ 0.9084,  0.9376,  0.9522,  ...,  1.7552,  1.7552,  1.7552],\n          [ 0.9376,  0.9376,  0.9668,  ...,  1.7552,  1.7552,  1.7552],\n          ...,\n          [-0.7850, -0.7850, -0.7266,  ..., -0.3178, -0.2740, -0.3616],\n          [-0.7558, -0.7558, -0.7412,  ..., -0.3178, -0.3616, -0.4346],\n          [-0.7558, -0.7704, -0.7850,  ..., -0.3616, -0.4346, -0.4784]],\n\n         [[ 1.2194,  1.2495,  1.2795,  ...,  1.8948,  1.8948,  1.8948],\n          [ 1.2344,  1.2645,  1.2945,  ...,  1.8948,  1.8948,  1.8948],\n          [ 1.2495,  1.2795,  1.3095,  ...,  1.8948,  1.8948,  1.8948],\n          ...,\n          [-0.5965, -0.5965, -0.5515,  ..., -0.4014, -0.3264, -0.4164],\n          [-0.5665, -0.5665, -0.5515,  ..., -0.3864, -0.4164, -0.4914],\n          [-0.5665, -0.5815, -0.5965,  ..., -0.4164, -0.4764, -0.5365]],\n\n         [[ 1.2927,  1.3211,  1.3496,  ...,  1.9753,  1.9753,  1.9753],\n          [ 1.3211,  1.3354,  1.3638,  ...,  1.9753,  1.9753,  1.9753],\n          [ 1.3354,  1.3496,  1.3780,  ...,  1.9753,  1.9753,  1.9753],\n          ...,\n          [-0.3568, -0.3426, -0.2857,  ..., -0.2573, -0.2146, -0.2857],\n          [-0.3142, -0.3000, -0.3000,  ..., -0.2573, -0.2857, -0.3568],\n          [-0.3142, -0.3426, -0.3568,  ..., -0.3000, -0.3568, -0.3995]]]]), 'input_ids': tensor([[ 101, 2129, 2116, 6077, 2024, 1999, 1996, 3861, 1029,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}]},{"cell_type":"code","source":"model.vision_model.forward (inputs[\"pixel_values\"]).keys()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:33:03.296348Z","iopub.execute_input":"2024-02-29T08:33:03.297199Z","iopub.status.idle":"2024-02-29T08:33:03.999973Z","shell.execute_reply.started":"2024-02-29T08:33:03.297161Z","shell.execute_reply":"2024-02-29T08:33:03.999022Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"odict_keys(['last_hidden_state', 'pooler_output'])"},"metadata":{}}]},{"cell_type":"code","source":"model.text_encoder = vi_model.embeddings ","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:40:00.860354Z","iopub.execute_input":"2024-03-02T05:40:00.860731Z","iopub.status.idle":"2024-03-02T05:40:00.865670Z","shell.execute_reply.started":"2024-03-02T05:40:00.860702Z","shell.execute_reply":"2024-03-02T05:40:00.864604Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.text_encoder","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:40:30.668855Z","iopub.execute_input":"2024-03-02T05:40:30.669283Z","iopub.status.idle":"2024-03-02T05:40:30.676191Z","shell.execute_reply.started":"2024-03-02T05:40:30.669255Z","shell.execute_reply":"2024-03-02T05:40:30.675131Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RobertaEmbeddings(\n  (word_embeddings): Embedding(64001, 768, padding_idx=1)\n  (position_embeddings): Embedding(258, 768, padding_idx=1)\n  (token_type_embeddings): Embedding(1, 768)\n  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:40:01.701789Z","iopub.execute_input":"2024-03-02T05:40:01.702905Z","iopub.status.idle":"2024-03-02T05:40:01.713842Z","shell.execute_reply.started":"2024-03-02T05:40:01.702860Z","shell.execute_reply":"2024-03-02T05:40:01.712822Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"BlipForQuestionAnswering(\n  (vision_model): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_encoder): RobertaEmbeddings(\n    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n    (position_embeddings): Embedding(258, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (text_decoder): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.text_decoder","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:30:42.335386Z","iopub.execute_input":"2024-02-29T08:30:42.336358Z","iopub.status.idle":"2024-02-29T08:30:42.345051Z","shell.execute_reply.started":"2024-02-29T08:30:42.336323Z","shell.execute_reply":"2024-02-29T08:30:42.344130Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"BlipTextLMHeadModel(\n  (bert): BlipTextModel(\n    (embeddings): BlipTextEmbeddings(\n      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): BlipTextEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BlipTextLayer(\n          (attention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (crossattention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): BlipTextIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BlipTextOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BlipTextOnlyMLMHead(\n    (predictions): BlipTextLMPredictionHead(\n      (transform): BlipTextPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=30524, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}